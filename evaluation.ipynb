{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a19d163",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "cbow_model = Word2Vec.load('cbow_vec/word2vec_our.model')\n",
    "mat_model = Word2Vec.load('mat2vec/training/models/pretrained_embeddings')\n",
    "skip_model = Word2Vec.load('skip_vec/word2vec_our.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d03f14c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18218\n",
      "4249\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('mat_dict.json', 'r', encoding='utf-8') as f:\n",
    "    mat_dict = json.load(f)\n",
    "print(len(mat_dict.keys()))   \n",
    "etl_score = {}\n",
    "with open('etl_score.txt', 'r', encoding='utf-8') as f:\n",
    "    etl = f.readlines()\n",
    "    for e in etl:\n",
    "        es = e[:-1].split('\\t')\n",
    "        etl_score[es[0]] = es[1]\n",
    "        \n",
    "htl_score = {}\n",
    "with open('htl_score.txt', 'r', encoding='utf-8') as f:\n",
    "    htl = f.readlines()\n",
    "    for h in htl:\n",
    "        hs = h[:-1].split('\\t')\n",
    "        htl_score[hs[0]] = hs[1]  \n",
    "        \n",
    "with open('pair_list.json', 'r', encoding='utf-8') as f:\n",
    "    pairs = json.load(f)\n",
    "print(len(pairs))\n",
    "# 4251 nomalization of abbrev\n",
    "# arrange normalization by length (long first)\n",
    "    \n",
    "# based dictionary of materials\n",
    "max_abbs = []\n",
    "for p in pairs:\n",
    "    max_abbs.append(p['max_abb'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70c3d62",
   "metadata": {},
   "source": [
    "## word2vec evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1966291e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def model_eval(model, tl_):\n",
    "    word_vectors = model.wv\n",
    "    length = len(word_vectors.key_to_index)\n",
    "    print(length)\n",
    "    passivation_sims = word_vectors.most_similar('passivation', topn=length)\n",
    "    contact_sims = word_vectors.most_similar('contact', topn=length)\n",
    "    # contact_sims = word_vectors.most_similar('selectivity', topn=length)\n",
    "    conductivity_sims = word_vectors.most_similar('conductivity', topn=length)\n",
    "    passivation = word_vectors['passivation']\n",
    "    contact = word_vectors['contact']\n",
    "    # contact = word_vectors['selectivity']\n",
    "    conductivity = word_vectors['conductivity']\n",
    "    combine_vec = (passivation + contact) / 2\n",
    "    combine_sims = word_vectors.most_similar(positive=[combine_vec], topn=length)\n",
    "    combine_vec3 = (passivation + contact + conductivity) / 3\n",
    "    combine_sims3 = word_vectors.most_similar(positive=[combine_vec3], topn=length)\n",
    "    position = 0\n",
    "    count = 0\n",
    "    first_500 = 0\n",
    "    tmp = 0\n",
    "    test = []\n",
    "    with open('skip_cbm3.csv', 'w', encoding='utf-8',newline='') as csvfile:\n",
    "        f = csv.writer(csvfile)\n",
    "        f.writerow(['rank','name','freq_N', 'freq_Y'])\n",
    "        for p_set in combine_sims3:\n",
    "            p = p_set[0]\n",
    "            if p in mat_dict.keys():\n",
    "                if 'Y' in mat_dict[p].keys():\n",
    "                    y = mat_dict[p]['Y']\n",
    "                else:\n",
    "                    y = 0\n",
    "                if 'N' in mat_dict[p].keys():\n",
    "                    n = mat_dict[p]['N']\n",
    "                else:\n",
    "                    n = 0\n",
    "                if n+y>3:\n",
    "                    tmp += 1            \n",
    "                    f.writerow([str(tmp),p,str(n), str(y)])\n",
    "            if p in list(tl_.keys())[:30]:\n",
    "                test.append(p)\n",
    "                position += tmp\n",
    "                count += 1\n",
    "                if tmp < 500:\n",
    "                    first_500 += 1\n",
    "    for t in list(tl_.keys())[:30]:\n",
    "        if t not in test:\n",
    "            print(t)\n",
    "    print(position, count)\n",
    "    return position/count, first_500            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eca3bdfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "112787\n",
      "123654 30\n",
      "(4121.8, 0)\n"
     ]
    }
   ],
   "source": [
    "print(model_eval(skip_model, htl_score))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481f953b",
   "metadata": {},
   "source": [
    "## BERT Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd507d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81517 30\n",
      "2717.233333333333 7\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# with open('MatSciBERT/sorted_score3.json', 'r', encoding='utf-8') as f:\n",
    "# mat_bert/sorted_score_sen.json\n",
    "with open('checkpoint-280000/sorted_score_our.json', 'r', encoding='utf-8') as f:\n",
    "    bert_sims = json.load(f)\n",
    "position = 0\n",
    "count = 0\n",
    "first_500 = 0\n",
    "tmp = 0\n",
    "test = []\n",
    "tl_ = etl_score\n",
    "with open('bert_sen_ber_cbm.csv', 'w', encoding='utf-8',newline='') as csvfile:\n",
    "    f = csv.writer(csvfile)\n",
    "    f.writerow(['rank','name','freq_N', 'freq_Y'])\n",
    "    for b_set in bert_sims:\n",
    "        b = b_set[0]\n",
    "        if b in mat_dict.keys():\n",
    "            if 'Y' in mat_dict[b].keys():\n",
    "                y = mat_dict[b]['Y']\n",
    "            else:\n",
    "                y = 0\n",
    "            if 'N' in mat_dict[b].keys():\n",
    "                n = mat_dict[b]['N']\n",
    "            else:\n",
    "                n = 0\n",
    "            if n+y>3:\n",
    "                tmp += 1            \n",
    "                f.writerow([str(tmp),b,str(n), str(y)])\n",
    "            if b in list(tl_.keys())[:30]:\n",
    "                test.append(b)\n",
    "                position += tmp\n",
    "                count += 1\n",
    "                if tmp < 500:\n",
    "                    first_500 += 1\n",
    "for t in list(tl_.keys())[:30]:\n",
    "    if t not in test:\n",
    "        print(t)\n",
    "print(position, count)\n",
    "print(position/count, first_500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b279ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cbow combine_sims3 etl, 28248 30 941.6, 17\n",
    "# cbow combine_sims3 htl, 34515 30 1150.5, 13\n",
    "# cbow combine_sims etl, 29356 30 978.53, 16\n",
    "# cbow combine_sims htl, 35232 30 1174.4, 14\n",
    "\n",
    "# skip combine_sims3 etl, 88311 30 2943.7, 0\n",
    "# skip combine_sims3 htl, 123654 30 4121.8, 0\n",
    "# skip combine_sims etl, 87639 30 2921.3, 2 \n",
    "# skip combine_sims htl, 126369 30 4212.3, 1\n",
    "\n",
    "# mat combine_sims3 etl, 52933 30 1764.43, 3\n",
    "# mat combine_sims3 htl, 58482 27 2166.0, 3\n",
    "# mat combine_sims etl, 58668 30 1955.6, 4 \n",
    "# mat combine_sims htl, 55769 27 2065.52, 2\n",
    "\n",
    "# bert_d_ind combine_sims3 etl,90383 30 3012.77 4\n",
    "# bert_d_ind combine_sims3 htl,78509 30 2616.97 7\n",
    "# bert_d_ind combine_sims etl,92371 30 3079.03 2 \n",
    "# bert_d_ind combine_sims htl,82341 30 2744.7 5\n",
    "\n",
    "# bert_d_ber combine_sims3 etl,79874 30 2662.47 3\n",
    "# bert_d_ber combine_sims3 htl,55485 30 1849.5 4\n",
    "# bert_d_ber combine_sims etl,79874 30 2662.47 3 \n",
    "# bert_d_ber combine_sims htl,55485 30 1849.5 4\n",
    "\n",
    "# bert_d_our \n",
    "\n",
    "\n",
    "# ber\n",
    "# v_test = get_embedding2('contactpassivationconductivity', 'contact passivation conductivity', tokenizer, model)\n",
    "# bert_a combine_sims3 etl,54017 30 1800.56 8\n",
    "# bert_a combine_sims3 htl,56665 30 1888.83 6\n",
    "\n",
    "# v_test = get_embedding2('contactpassivation', 'contact passivation', tokenizer, model)\n",
    "# bert_a combine_sims etl, 42096 30 1403.2 9\n",
    "# bert_a combine_sims htl,61032 30 2034.4 5\n",
    "\n",
    "# v_test = get_embedding2('contactpassivation', 'contact passivation conductivity', tokenizer, model)\n",
    "# bert_a combine_sims etl, 43382 30 1446.07 11\n",
    "# bert_a combine_sims htl,58780 30 1959.33 4\n",
    "\n",
    "# v1 = get_embedding1('passivation', tokenizer, model)\n",
    "# v = torch.mean(torch.stack([v1, v2, v3]), 0)\n",
    "# bert_a combine_sims etl,43678 30 1455.93 7\n",
    "# bert_a combine_sims htl,67068 30 2235.6 4\n",
    "\n",
    "# sen\n",
    "# sen = 'passivation, conductivity, and selectivity are often acknowledged as the three requirements for optimal ' \\\n",
    "      # 'contacts to photovoltaic solar cells '\n",
    "# v1 = get_embedding2('conductivity', sen, tokenizer, model)\n",
    "# v2 = get_embedding2('passivation', sen, tokenizer, model)\n",
    "# v3 = get_embedding2('selectivity', sen, tokenizer, model)\n",
    "# bert_a_ber combine_sims etl,48623 30 1620.76 11\n",
    "# bert_a_ber combine_sims htl,45402 30 1513.4 9\n",
    "# bert_a_our combine_sims etl,\n",
    "# bert_a_our combine_sims htl,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1329199a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
