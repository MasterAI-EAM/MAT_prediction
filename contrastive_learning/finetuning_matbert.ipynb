{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f431b826-9ac8-4a57-90f3-5ad5fc0e1861",
   "metadata": {},
   "source": [
    "# finetuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45b57b2b-fc20-4f14-b46a-b30a0c663c5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\envs\\hugging\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "D:\\Anaconda3\\envs\\hugging\\lib\\site-packages\\numpy\\.libs\\libopenblas.QVLO2T66WEPI7JZ63PS3HMOHFEY472BC.gfortran-win_amd64.dll\n",
      "D:\\Anaconda3\\envs\\hugging\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sentence_transformers import InputExample, datasets\n",
    "from sentence_transformers import models, losses, SentenceTransformer\n",
    "from sentence_transformers import LoggingHandler\n",
    "import logging "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75442fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.10.0+cpu\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 检查cuda\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0761a827-c805-4790-86df-b10c7e956758",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format=\"%(asctime)s - %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    "    handlers=[LoggingHandler()]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcc3bec-6750-4724-b5c6-0f3052ad30c4",
   "metadata": {},
   "source": [
    "## data - input_samples - dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f31eeb37-f935-45b9-a949-bb7f68dd3a3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10329\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('formulae_synonyms_descriptions.csv')\n",
    "data = df[df['description'] != 'NO DESCRIPTION']\n",
    "\n",
    "form_syn = data[['formula', 'synonym']]\n",
    "syn_desc = data[['synonym', 'description']]\n",
    "form_desc = data[['formula', 'description']]\n",
    "\n",
    "data_pairs = pd.concat([form_syn, syn_desc, form_desc])\n",
    "print(len(data_pairs))   # need to split the data into train-val-test???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b9583a4-afce-417a-9332-08ab0c3bd8c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pairs(row):\n",
    "    a = row.iloc[0]\n",
    "    b = row.iloc[1]\n",
    "    sample = InputExample(texts=[str(a), str(b)])   # represent one input which contains texts and label???\n",
    "    return sample\n",
    "\n",
    "samples = list(data_pairs.apply(extract_pairs, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8d40067-10c9-43eb-812e-d7a8f131e5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "dataloader = datasets.NoDuplicatesDataLoader(samples, batch_size=batch_size)\n",
    "# help(datasets)\n",
    "# NoDuplicatesDataLoader, used with MultipleNegativesRankingLoss\n",
    "# ParallelSentencesDataset, to read-in tab-separated parallel sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa796d14-6ca4-4624-98c7-3fb29fd84128",
   "metadata": {},
   "source": [
    "## matbert + pooler = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61b422c9-7c38-428b-9eb1-714751db751d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertModel were not initialized from the model checkpoint at C:/Users/Lenovo/Desktop/EnergyBERT/mat_bert_cased and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# C:/Users/Lenovo/Desktop/EnergyBERT/mat_bert_cased\n",
    "model_path = 'C:/Users/Lenovo/Desktop/EnergyBERT/mat_bert_cased'\n",
    "max_seq_length = 128\n",
    "matbert = models.Transformer(model_path, max_seq_length)   # word embedding model\n",
    "\n",
    "# help(models.Pooling)\n",
    "embedding_dimension = matbert.get_word_embedding_dimension()\n",
    "pooler = models.Pooling(embedding_dimension, pooling_mode=\"mean_sqrt_len_tokens\")   # extract third layer???\n",
    "# mean_sqrt_len_tokens: mean-pooling but divide by square of input_length, reduce the impact of sequence length on pooling operation\n",
    "# cls/max/mean/lasttoken/weightdmean(position weighted mean pooling)\n",
    "\n",
    "model = SentenceTransformer(modules=[matbert, pooler],device='cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd08e4ce-8e87-4450-9df9-236c5bb533c4",
   "metadata": {},
   "source": [
    "## training with MNR loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b68ec87b-0649-4250-b5fe-505288e31432",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = losses.MultipleNegativesRankingLoss(model)   # other loss function???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b98aeef-8dbd-4872-bc2a-76f5f4701ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e22c8c6c1ed4468a93c317fc7e2067b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3fd0dbeb8a24652bf9e3c7e3e4c131f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22fcdbb6d8b1431e8208ef0c16975f57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efa36fc92ebb4ce7b4032ca81b168869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cf210bd7d7472bb7d1f11ff8b316d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da13043cf590464a97b7989fde84dd0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/322 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-04-22 17:10:14 - Save model to outputs/matbert_mnr\n"
     ]
    }
   ],
   "source": [
    "epochs = 5   # use validation sets to determine appropriate number of epochs to avoid overfitting and achieve the best performance???\n",
    "warmup_steps = int(len(dataloader) * epochs * 0.1)\n",
    "output_path = 'outputs/matbert_mnr'\n",
    "\n",
    "# help(model.fit)\n",
    "# param evaluator: (sentence_transformers.evaluation) evaluates the model performance during training on held-out dev data\n",
    "# param save_best_model: if true, the best model according to the evaluator is stored at output_path\n",
    "# param optimizer_class: Optimizer; param optimizer_params: Optimizer parameters, default {'lr': 2e-05(2*10^-5)}\n",
    "# lr (learning rate): a hyperparameter that controls how much the model's parameters are updated during each training step\n",
    "# usually range from 1e-4 to 1e-6, lower learning rate can be more stable, better to start with a small learning rate\n",
    "model.fit(\n",
    "    train_objectives=[(dataloader, loss)],\n",
    "    epochs=epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    output_path=output_path,\n",
    "    show_progress_bar=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322364b4-fe53-48f3-81d3-07351c487ef8",
   "metadata": {},
   "source": [
    "# downstream task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed685b11-4791-4890-905c-81ae82e685c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from scipy.spatial.distance import cosine\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0db99fa3-9e83-48e8-93fb-3cae60c8c937",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../for_spearman/zt_ori_84.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    names = [line.strip().split('\\t')[0] for line in lines]\n",
    "    zt_scores = [line.strip().split('\\t')[-1] for line in lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17787ff4-356b-4b68-a33e-c1d3c66a3c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You try to use a model that was created with version 2.7.0, however, your version is 2.2.2. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'pooling_mode_weightedmean_tokens'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[5], line 2\u001B[0m\n\u001B[0;32m      1\u001B[0m output_path \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124moutputs/matbert_mnr\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m----> 2\u001B[0m tuned_model \u001B[38;5;241m=\u001B[39m \u001B[43mSentenceTransformer\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      4\u001B[0m center_embedding \u001B[38;5;241m=\u001B[39m tuned_model\u001B[38;5;241m.\u001B[39mencode(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mthermoelectric\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m name_embeddings \u001B[38;5;241m=\u001B[39m tuned_model\u001B[38;5;241m.\u001B[39mencode(names)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\hugging\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:95\u001B[0m, in \u001B[0;36mSentenceTransformer.__init__\u001B[1;34m(self, model_name_or_path, modules, device, cache_folder, use_auth_token)\u001B[0m\n\u001B[0;32m     87\u001B[0m         snapshot_download(model_name_or_path,\n\u001B[0;32m     88\u001B[0m                             cache_dir\u001B[38;5;241m=\u001B[39mcache_folder,\n\u001B[0;32m     89\u001B[0m                             library_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentence-transformers\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m     90\u001B[0m                             library_version\u001B[38;5;241m=\u001B[39m__version__,\n\u001B[0;32m     91\u001B[0m                             ignore_files\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mflax_model.msgpack\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrust_model.ot\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtf_model.h5\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[0;32m     92\u001B[0m                             use_auth_token\u001B[38;5;241m=\u001B[39muse_auth_token)\n\u001B[0;32m     94\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mexists(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(model_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodules.json\u001B[39m\u001B[38;5;124m'\u001B[39m)):    \u001B[38;5;66;03m#Load as SentenceTransformer model\u001B[39;00m\n\u001B[1;32m---> 95\u001B[0m     modules \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_load_sbert_model\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:   \u001B[38;5;66;03m#Load with AutoModel\u001B[39;00m\n\u001B[0;32m     97\u001B[0m     modules \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_load_auto_model(model_path)\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\hugging\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:840\u001B[0m, in \u001B[0;36mSentenceTransformer._load_sbert_model\u001B[1;34m(self, model_path)\u001B[0m\n\u001B[0;32m    838\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m module_config \u001B[38;5;129;01min\u001B[39;00m modules_config:\n\u001B[0;32m    839\u001B[0m     module_class \u001B[38;5;241m=\u001B[39m import_from_string(module_config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtype\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m--> 840\u001B[0m     module \u001B[38;5;241m=\u001B[39m \u001B[43mmodule_class\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43mos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpath\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodule_config\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mpath\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    841\u001B[0m     modules[module_config[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mname\u001B[39m\u001B[38;5;124m'\u001B[39m]] \u001B[38;5;241m=\u001B[39m module\n\u001B[0;32m    843\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m modules\n",
      "File \u001B[1;32mD:\\Anaconda3\\envs\\hugging\\lib\\site-packages\\sentence_transformers\\models\\Pooling.py:120\u001B[0m, in \u001B[0;36mPooling.load\u001B[1;34m(input_path)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(input_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig.json\u001B[39m\u001B[38;5;124m'\u001B[39m)) \u001B[38;5;28;01mas\u001B[39;00m fIn:\n\u001B[0;32m    118\u001B[0m     config \u001B[38;5;241m=\u001B[39m json\u001B[38;5;241m.\u001B[39mload(fIn)\n\u001B[1;32m--> 120\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPooling\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'pooling_mode_weightedmean_tokens'"
     ]
    }
   ],
   "source": [
    "output_path = 'outputs/matbert_mnr'\n",
    "tuned_model = SentenceTransformer(output_path)\n",
    "\n",
    "center_embedding = tuned_model.encode('thermoelectric')\n",
    "name_embeddings = tuned_model.encode(names)\n",
    "\n",
    "cos_sims = [(1-cosine(center_embedding,name_embedding)) for name_embedding in name_embeddings]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9972a4ac-37e4-4175-ab5d-40fd9a3a9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr, pvalue = stats.spearmanr(cos_sims, zt_scores)\n",
    "print('spearman correlation', corr)   # (vega) result: 0.3367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c875fd9e-7eee-4c84-a30f-f26a388392b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}